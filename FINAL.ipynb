{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation: Imports, functions and Audio Trim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import essentia.standard as es\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import soundfile as sf\n",
    "from keras.models import load_model\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_wave(wave, idx):\n",
    "    frame_size = len(wave)\n",
    "    pitchYin = es.PitchYin(frameSize=frame_size)\n",
    "    pitch, pitchconf = pitchYin(wave)\n",
    "    print(pitch, pitchconf)\n",
    "    if pitchconf < 0.8:\n",
    "        raise ValueError(\"Pitch confidence too low\")\n",
    "    period = 1.0 / pitch\n",
    "    period_samples = int(period * 44100)\n",
    "\n",
    "    zero_crossings = np.where(np.diff(np.sign(wave)) > 0)[0]\n",
    "    if len(zero_crossings) > 0:\n",
    "        start = zero_crossings[0]\n",
    "        trimmed_wave = wave[start : start + period_samples]\n",
    "    else:\n",
    "        trimmed_wave = wave[:period_samples]\n",
    "\n",
    "    return trimmed_wave\n",
    "\n",
    "\n",
    "def frequency(waves):\n",
    "    for wave in waves:\n",
    "        pitchYin = es.PitchYin(frameSize=len(wave))\n",
    "        pitch, pitchconf = pitchYin(wave)\n",
    "        print(pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '1.1.wav', '1.2.wav', '1.3.wav', '1.4.wav', '1.5.wav', '1.6.wav', '2.1.wav', '2.2.wav', '2.3.wav', '2.4.wav', '2.5.wav', '2.6.wav', '3.1.wav', '3.2.wav', '3.3.wav', '3.4.wav', '3.5.wav', '3.6.wav', '4.1.wav', '4.2.wav']\n",
      "440.05621337890625 0.9994421601295471\n",
      "440.03936767578125 0.9994345307350159\n",
      "440.11334228515625 0.9992413520812988\n",
      "440.09478759765625 0.9993952512741089\n",
      "440.1029968261719 0.9989595413208008\n",
      "440.0918884277344 0.9986041188240051\n",
      "440.1206970214844 0.9982636570930481\n",
      "440.1067810058594 0.9974650144577026\n",
      "440.218017578125 0.9980720281600952\n",
      "440.10198974609375 0.9990507960319519\n",
      "440.08587646484375 0.9987959861755371\n",
      "440.09356689453125 0.9973345398902893\n",
      "440.0983581542969 0.9991087317466736\n",
      "440.05987548828125 0.9990563988685608\n",
      "440.07025146484375 0.9989929795265198\n",
      "440.05804443359375 0.9983398914337158\n",
      "440.056640625 0.995542049407959\n",
      "440.0585021972656 0.995547354221344\n",
      "440.052734375 0.99550861120224\n",
      "440.06170654296875 0.9955691695213318\n",
      "[0.         0.21052632 0.42105263 0.63157895 0.84210526 1.05263158\n",
      " 1.26315789 1.47368421 1.68421053 1.89473684 2.10526316 2.31578947\n",
      " 2.52631579 2.73684211 2.94736842 3.15789474 3.36842105 3.57894737\n",
      " 3.78947368 4.        ]\n"
     ]
    }
   ],
   "source": [
    "audio_dir = \"def samples\"\n",
    "audio_files = sorted(os.listdir(audio_dir))\n",
    "print(audio_files)\n",
    "audio_data = []\n",
    "for file in audio_files:\n",
    "    if file.endswith(\".wav\"):\n",
    "        loader = es.MonoLoader(filename=os.path.join(audio_dir, file), sampleRate=44100)\n",
    "        audio = loader()\n",
    "        audio_data.append(audio)\n",
    "audio_data = np.array(audio_data)\n",
    "audio_data_trimmed = []\n",
    "for i in range(len(audio_data)):\n",
    "    wave = audio_data[i]\n",
    "    trimmed_wave = trim_wave(wave, i)\n",
    "    audio_data_trimmed.append(trimmed_wave)\n",
    "\n",
    "audios = np.array(audio_data_trimmed)\n",
    "# pot_values = np.linspace(0, 4, len(audio_data_trimmed))\n",
    "pot_values = np.linspace(0, 4, len(audio_data_trimmed))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_output_lininter(pot_value, pot_values=pot_values, audios=audios):\n",
    "    if pot_value < 0 or pot_value > 4:\n",
    "        raise ValueError(\"Pot value must be between 0 and 4\")\n",
    "    interpolator = interp1d(pot_values, audios, axis=0, kind=\"linear\")\n",
    "    return interpolator(pot_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_depth\": [None, 5, 10, 15, 20, 25, 30],\n",
    "    \"min_samples_split\": [2, 5, 10, 15, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10, 15],\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf_grid = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1)\n",
    "rf_grid.fit(pot_values.reshape(-1, 1), audios[:, 0])\n",
    "best_params = rf_grid.best_params_\n",
    "print(best_params)\n",
    "\n",
    "models = [\n",
    "    RandomForestRegressor(\n",
    "        n_estimators=best_params[\"n_estimators\"],\n",
    "        max_depth=best_params[\"max_depth\"],\n",
    "        min_samples_split=best_params[\"min_samples_split\"],\n",
    "        min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "    ).fit(pot_values.reshape(-1, 1), audios[:, i])\n",
    "    for i in range(audios.shape[1])\n",
    "]\n",
    "\n",
    "\n",
    "def predicted_RF(pot_value):\n",
    "    return np.array([model.predict([[pot_value]])[0] for model in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_output_RF = []\n",
    "for pot_value in pot_values:\n",
    "    predicted_output_RF.append(predicted_RF(pot_value))\n",
    "predicted_output_RF = np.array(predicted_output_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mmodel_RF.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "dump(models, \"models_RF.joblib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the pot_values\n",
    "scaler = StandardScaler()\n",
    "pot_values_scaled = scaler.fit_transform(pot_values.reshape(-1, 1))\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, input_shape=(None, 1))))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(audios.shape[1]))  # Adjusted to match the number of output samples\n",
    "\n",
    "# Compile the model with a smaller learning rate\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=opt)\n",
    "\n",
    "# Create the ReduceLROnPlateau callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.95, patience=25, min_delta=5e-7)\n",
    "\n",
    "# Reshape the data to fit the model\n",
    "X = pot_values_scaled.reshape(len(pot_values_scaled), 1, 1)\n",
    "Y = audios\n",
    "\n",
    "# Train the model for more epochs with the ReduceLROnPlateau callback\n",
    "model.fit(X, Y, epochs=3000, batch_size=128, callbacks=[reduce_lr], verbose=0)\n",
    "\n",
    "\n",
    "# Define a function to make predictions\n",
    "def predicted_RNN(pot_value):\n",
    "    pot_value_scaled = scaler.transform(np.array([[pot_value]]))\n",
    "    return model.predict(pot_value_scaled.reshape(1, 1, 1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_RNN_values = np.array([predicted_RNN(pot_value) for pot_value in pot_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_RNN.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(predicted_output_RF) == len(audio_data_trimmed)\n",
    "mse_vals_rf = []\n",
    "for predicted_output_val, audio_data_trim in zip(\n",
    "    predicted_output_RF, audio_data_trimmed\n",
    "):\n",
    "    mse_vals_rf.append(mean_squared_error(predicted_output_val, audio_data_trim))\n",
    "\n",
    "plt.bar(range(len(mse_vals_rf)), mse_vals_rf)\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n",
    "print(np.mean(mse_vals_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predicted_output_RF[1], label=\"RF\")\n",
    "plt.plot(audios[1], label=\"Original\")\n",
    "plt.title(\"Comparison for index 1, pot_value = 0.21052632\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predicted_output_RF[12], label=\"RF\")\n",
    "plt.plot(audios[12], label=\"Original\")\n",
    "plt.title(\"Comparison for index 12, pot_value =  2.52631579\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(predicted_RNN_values) == len(audio_data_trimmed)\n",
    "mse_vals_rnn = []\n",
    "for predicted_output_val, audio_data_trim in zip(\n",
    "    predicted_RNN_values, audio_data_trimmed\n",
    "):\n",
    "    mse_vals_rnn.append(mean_squared_error(predicted_output_val, audio_data_trim))\n",
    "\n",
    "plt.bar(range(len(mse_vals_rnn)), mse_vals_rnn)\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n",
    "print(np.mean(mse_vals_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predicted_RNN_values[16], label=\"RNN\")\n",
    "plt.plot(audios[16], label=\"Original\")\n",
    "plt.title(\"Comparison for index 16, pot_value =  3.36842105\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predicted_RNN_values[18], label=\"RNN\")\n",
    "plt.plot(audios[18], label=\"Original\")\n",
    "plt.title(\"Comparison for index 18, pot_value =  3.78947368\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_values_new = []\n",
    "for i in range(len(pot_values) - 1):\n",
    "    pot_values_new.append((pot_values[i] + pot_values[i + 1]) / 2)\n",
    "print(pot_values_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_pred_LI = []\n",
    "inter_pred_RNN = []\n",
    "inter_pred_RF = []\n",
    "for pot_value in pot_values_new:\n",
    "    inter_pred_LI.append(predicted_output_lininter(pot_value))\n",
    "    inter_pred_RNN.append(predicted_RNN(pot_value))\n",
    "    inter_pred_RF.append(predicted_RF(pot_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(inter_pred_LI) == len(inter_pred_RNN)\n",
    "mse_vals_rnn_LI = []\n",
    "for predicted_output_val, audio_data_trim in zip(inter_pred_LI, inter_pred_RNN):\n",
    "    mse_vals_rnn_LI.append(mean_squared_error(predicted_output_val, audio_data_trim))\n",
    "\n",
    "plt.bar(range(len(mse_vals_rnn_LI)), mse_vals_rnn_LI)\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for Linear Interpolation adn RNN\")\n",
    "plt.show()\n",
    "print(np.mean(mse_vals_rnn_LI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(inter_pred_LI) == len(inter_pred_RNN)\n",
    "mse_vals_RF_LI = []\n",
    "for predicted_output_val, audio_data_trim in zip(inter_pred_LI, inter_pred_RF):\n",
    "    mse_vals_RF_LI.append(mean_squared_error(predicted_output_val, audio_data_trim))\n",
    "\n",
    "plt.bar(range(len(mse_vals_RF_LI)), mse_vals_RF_LI)\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for Linear Interpolation and Random Forest\")\n",
    "plt.show()\n",
    "print(np.mean(mse_vals_RF_LI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(inter_pred_LI[1], label=\"linear interpolation\")\n",
    "plt.plot(inter_pred_RNN[1], label=\"RNN\")\n",
    "plt.plot(inter_pred_RF[1], label=\"RF\")\n",
    "plt.title(\"Comparison for index 1, pot_value =  0.3157894736842105\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pot_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audios[15], label=\"wave previous to pred\", color=\"red\")\n",
    "plt.plot(audios[16], label=\"wave next to pred\", color=\"black\")\n",
    "plt.fill_between(range(len(audios[15])), audios[15], audios[16], color=\"red\", alpha=0.1)\n",
    "plt.plot(inter_pred_LI[15], label=\"linear interpolation\", color=\"blue\")\n",
    "plt.plot(inter_pred_RNN[15], label=\"RNN\", color=\"green\")\n",
    "plt.plot(inter_pred_RF[15], label=\"RF\", color=\"orange\")\n",
    "plt.title(\"Comparison for index 15, pot_value =  3.263157894736842\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Graphs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pot_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pot_values)):\n",
    "    plt.plot(audios[i], label=\"original\", color=\"red\")\n",
    "    plt.plot(predicted_RNN_values[i], label=\"RNN\", color=\"green\")\n",
    "    plt.plot(predicted_output_RF[i], label=\"RF\", color=\"orange\")\n",
    "    plt.title(\"Comparison for index \" + str(i) + \", pot_value = \" + str(pot_values[i]))\n",
    "    plt.legend()\n",
    "\n",
    "    # plt.savefig(\"comparison_\" + str(i) + \".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inter_pot_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pot_values_new)):\n",
    "    plt.plot(inter_pred_LI[i], label=\"LI\", color=\"red\")\n",
    "    plt.plot(inter_pred_RF[i], label=\"RNN\", color=\"green\")\n",
    "    plt.plot(inter_pred_RNN[i], label=\"RF\", color=\"orange\")\n",
    "    plt.title(\n",
    "        \"Comparison for index \" + str(i) + \", pot_value_new = \" + str(pot_values[i])\n",
    "    )\n",
    "    plt.legend()\n",
    "\n",
    "    # plt.savefig(\"comparison_\" + str(i) + \".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_as_sound(audio, output_filename, length):\n",
    "    num_rep = int(length * 44100 / len(audio))\n",
    "    audio_strech = np.tile(audio, num_rep)\n",
    "    sf.write(output_filename, audio_strech, 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(pot_values)):\n",
    "#     create_and_save_as_sound(audios[i], \"original\" + str(i) + \".wav\", 2)\n",
    "#     create_and_save_as_sound(predicted_output_RF[i], \"RF\" + str(i) + \".wav\", 2)\n",
    "#     create_and_save_as_sound(predicted_RNN_values[i], \"RNN\" + str(i) + \".wav\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(pot_values_new)):\n",
    "#     create_and_save_as_sound(inter_pred_LI[i], \"LI\" + str(i) + \".wav\", 2)\n",
    "#     create_and_save_as_sound(inter_pred_RF[i], \"RF\" + str(i) + \".wav\", 2)\n",
    "#     create_and_save_as_sound(inter_pred_RNN[i], \"RNN\" + str(i) + \".wav\", 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lin Inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "a = predicted_output_lininter(0.5)\n",
    "stop = timeit.default_timer()\n",
    "print(\"Time: \", stop - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "a = predicted_RF(0.5)\n",
    "stop = timeit.default_timer()\n",
    "print(\"Time: \", stop - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "a = predicted_RNN(0.5)\n",
    "stop = timeit.default_timer()\n",
    "print(\"Time: \", stop - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
