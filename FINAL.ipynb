{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation: Imports, functions and Audio Trim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import essentia.standard as es\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import soundfile as sf\n",
    "from keras.models import load_model\n",
    "from joblib import load, dump\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_wave(wave, idx):\n",
    "    frame_size = len(wave)\n",
    "    pitchYin = es.PitchYin(frameSize=frame_size)\n",
    "    pitch, pitchconf = pitchYin(wave)\n",
    "    print(pitch, pitchconf)\n",
    "    if pitchconf < 0.8:\n",
    "        raise ValueError(\"Pitch confidence too low\")\n",
    "    period = 1.0 / pitch\n",
    "    period_samples = int(period * 44100)\n",
    "\n",
    "    zero_crossings = np.where(np.diff(np.sign(wave)) > 0)[0]\n",
    "    if len(zero_crossings) > 0:\n",
    "        start = zero_crossings[0]\n",
    "        trimmed_wave = wave[start : start + period_samples]\n",
    "    else:\n",
    "        trimmed_wave = wave[:period_samples]\n",
    "\n",
    "    return trimmed_wave\n",
    "\n",
    "\n",
    "def frequency(waves):\n",
    "    for wave in waves:\n",
    "        pitchYin = es.PitchYin(frameSize=len(wave))\n",
    "        pitch, pitchconf = pitchYin(wave)\n",
    "        print(pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = \"def samples\"\n",
    "audio_files = sorted(os.listdir(audio_dir))\n",
    "print(audio_files)\n",
    "audio_data = []\n",
    "for file in audio_files:\n",
    "    if file.endswith(\".wav\"):\n",
    "        loader = es.MonoLoader(filename=os.path.join(audio_dir, file), sampleRate=44100)\n",
    "        audio = loader()\n",
    "        audio_data.append(audio)\n",
    "audio_data = np.array(audio_data)\n",
    "audio_data_trimmed = []\n",
    "for i in range(len(audio_data)):\n",
    "    wave = audio_data[i]\n",
    "    trimmed_wave = trim_wave(wave, i)\n",
    "    audio_data_trimmed.append(trimmed_wave)\n",
    "\n",
    "audios = np.array(audio_data_trimmed)\n",
    "# pot_values = np.linspace(0, 4, len(audio_data_trimmed))\n",
    "pot_values = np.linspace(0, 4, len(audio_data_trimmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pot_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_output_lininter(pot_value, pot_values=pot_values, audios=audios):\n",
    "    if pot_value < 0 or pot_value > 4:\n",
    "        raise ValueError(\"Pot value must be between 0 and 4\")\n",
    "    interpolator = interp1d(pot_values, audios, axis=0, kind=\"linear\")\n",
    "    return interpolator(pot_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_depth\": [None, 5, 10, 15, 20, 25, 30],\n",
    "    \"min_samples_split\": [2, 5, 10, 15, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 5, 10, 15],\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf_grid = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1)\n",
    "rf_grid.fit(pot_values.reshape(-1, 1), audios[:, 0])\n",
    "best_params = rf_grid.best_params_\n",
    "print(best_params)\n",
    "\n",
    "models = [\n",
    "    RandomForestRegressor(\n",
    "        n_estimators=best_params[\"n_estimators\"],\n",
    "        max_depth=best_params[\"max_depth\"],\n",
    "        min_samples_split=best_params[\"min_samples_split\"],\n",
    "        min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "    ).fit(pot_values.reshape(-1, 1), audios[:, i])\n",
    "    for i in range(audios.shape[1])\n",
    "]\n",
    "\n",
    "\n",
    "def predicted_RF(pot_value):\n",
    "    return np.array([model.predict([[pot_value]])[0] for model in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_output_RF = []\n",
    "for pot_value in pot_values:\n",
    "    predicted_output_RF.append(predicted_RF(pot_value))\n",
    "predicted_output_RF = np.array(predicted_output_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(models, \"models_RF.joblib\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the pot_values\n",
    "scaler = StandardScaler()\n",
    "pot_values_scaled = scaler.fit_transform(pot_values.reshape(-1, 1))\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, input_shape=(None, 1))))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(audios.shape[1]))  # Adjusted to match the number of output samples\n",
    "\n",
    "# Compile the model with a smaller learning rate\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=opt)\n",
    "\n",
    "# Create the ReduceLROnPlateau callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.95, patience=25, min_delta=5e-7)\n",
    "\n",
    "# Reshape the data to fit the model\n",
    "X = pot_values_scaled.reshape(len(pot_values_scaled), 1, 1)\n",
    "Y = audios\n",
    "\n",
    "# Train the model for more epochs with the ReduceLROnPlateau callback\n",
    "model.fit(X, Y, epochs=3000, batch_size=128, callbacks=[reduce_lr], verbose=0)\n",
    "\n",
    "\n",
    "# Define a function to make predictions\n",
    "def predicted_RNN(pot_value):\n",
    "    pot_value_scaled = scaler.transform(np.array([[pot_value]]))\n",
    "    return model.predict(pot_value_scaled.reshape(1, 1, 1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_RNN_values = np.array([predicted_RNN(pot_value) for pot_value in pot_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"model_RNN.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(predicted_output_RF) == len(audio_data_trimmed)\n",
    "mse_vals_rf = []\n",
    "for predicted_output_val, audio_data_trim in zip(\n",
    "    predicted_output_RF, audio_data_trimmed\n",
    "):\n",
    "    mse_vals_rf.append(mean_squared_error(predicted_output_val, audio_data_trim))\n",
    "\n",
    "plt.bar(range(len(mse_vals_rf)), mse_vals_rf)\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for RF model\")\n",
    "plt.show()\n",
    "print(np.mean(mse_vals_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predicted_output_RF[1], label=\"RF\")\n",
    "plt.plot(audios[1], label=\"Original\")\n",
    "plt.title(\"Comparison for index 1, pot_value = 0.21052632\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predicted_output_RF[14], label=\"RF\")\n",
    "plt.plot(audios[14], label=\"Original\")\n",
    "plt.title(\"Comparison for index 14, pot_value =  2.94736842\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(predicted_RNN_values) == len(audio_data_trimmed)\n",
    "mse_vals_rnn = []\n",
    "for predicted_output_val, audio_data_trim in zip(\n",
    "    predicted_RNN_values, audio_data_trimmed\n",
    "):\n",
    "    mse_vals_rnn.append(mean_squared_error(predicted_output_val, audio_data_trim))\n",
    "\n",
    "plt.bar(range(len(mse_vals_rnn)), mse_vals_rnn)\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for RNN model\")\n",
    "plt.show()\n",
    "print(np.mean(mse_vals_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predicted_RNN_values[1], label=\"RNN\")\n",
    "plt.plot(audios[1], label=\"Original\")\n",
    "plt.title(\"Comparison for index 1, pot_value =  0.21052632\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predicted_RNN_values[18], label=\"RNN\")\n",
    "plt.plot(audios[18], label=\"Original\")\n",
    "plt.title(\"Comparison for index 18, pot_value =  3.78947368\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(mse_vals_rf)), mse_vals_rf, label=\"RF\")\n",
    "plt.bar(range(len(mse_vals_rnn)), mse_vals_rnn, label=\"RNN\")\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for RF and RNN models\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_values_new = []\n",
    "for i in range(len(pot_values) - 1):\n",
    "    pot_values_new.append((pot_values[i] + pot_values[i + 1]) / 2)\n",
    "print(pot_values_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_pred_LI = []\n",
    "inter_pred_RNN = []\n",
    "inter_pred_RF = []\n",
    "for pot_value in pot_values_new:\n",
    "    inter_pred_LI.append(predicted_output_lininter(pot_value))\n",
    "    inter_pred_RNN.append(predicted_RNN(pot_value))\n",
    "    inter_pred_RF.append(predicted_RF(pot_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(inter_pred_LI) == len(inter_pred_RNN)\n",
    "mse_vals_rnn_LI = []\n",
    "for predicted_output_val, audio_data_trim in zip(inter_pred_LI, inter_pred_RNN):\n",
    "    mse_vals_rnn_LI.append(mean_squared_error(predicted_output_val, audio_data_trim))\n",
    "\n",
    "plt.bar(range(len(mse_vals_rnn_LI)), mse_vals_rnn_LI)\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for Linear Interpolation and RNN\")\n",
    "plt.show()\n",
    "print(np.mean(mse_vals_rnn_LI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(inter_pred_LI) == len(inter_pred_RNN)\n",
    "mse_vals_RF_LI = []\n",
    "for predicted_output_val, audio_data_trim in zip(inter_pred_LI, inter_pred_RF):\n",
    "    mse_vals_RF_LI.append(mean_squared_error(predicted_output_val, audio_data_trim))\n",
    "\n",
    "plt.bar(range(len(mse_vals_RF_LI)), mse_vals_RF_LI)\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for Linear Interpolation and Random Forest\")\n",
    "plt.show()\n",
    "print(np.mean(mse_vals_RF_LI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(inter_pred_RF) == len(inter_pred_RNN)\n",
    "mse_vals_RF_RNN = []\n",
    "for predicted_output_val, audio_data_trim in zip(inter_pred_RNN, inter_pred_RF):\n",
    "    mse_vals_RF_RNN.append(mean_squared_error(predicted_output_val, audio_data_trim))\n",
    "\n",
    "plt.bar(range(len(mse_vals_RF_RNN)), mse_vals_RF_RNN)\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for RNN and Random Forest\")\n",
    "plt.show()\n",
    "print(np.mean(mse_vals_RF_RNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(inter_pred_LI[1], label=\"linear interpolation\")\n",
    "plt.plot(inter_pred_RNN[1], label=\"RNN\")\n",
    "plt.plot(inter_pred_RF[1], label=\"RF\")\n",
    "plt.title(\"Comparison for index 1, pot_value =  0.3157894736842105\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audios[9], label=\"wave previous to prediction\", color=\"red\")\n",
    "plt.plot(audios[10], label=\"wave next to prediction\", color=\"black\")\n",
    "plt.fill_between(range(len(audios[9])), audios[9], audios[10], color=\"red\", alpha=0.1)\n",
    "plt.plot(inter_pred_LI[9], label=\"linear interpolation\", color=\"blue\")\n",
    "plt.plot(inter_pred_RNN[9], label=\"RNN\", color=\"green\")\n",
    "plt.title(\"Comparison for index 9, pot_value = 2.0\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(mse_vals_rnn_LI)), mse_vals_rnn_LI, label=\"RNN_LI\", alpha=1)\n",
    "plt.bar(range(len(mse_vals_RF_LI)), mse_vals_RF_LI, label=\"RF_LI\", alpha=0.5)\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for Linear Interpolation and RNN\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(mse_vals_RF_RNN)), mse_vals_RF_RNN, label=\"RF_RNN\")\n",
    "plt.xlabel(\"Sample number\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE for RNN and Random Forest\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Graphs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pot_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(pot_values)):\n",
    "#     plt.plot(audios[i], label=\"original\", color=\"red\")\n",
    "#     plt.plot(predicted_RNN_values[i], label=\"RNN\", color=\"green\")\n",
    "#     plt.plot(predicted_output_RF[i], label=\"RF\", color=\"orange\")\n",
    "#     plt.title(\"Comparison for index \" + str(i) + \", pot_value = \" + str(pot_values[i]))\n",
    "#     plt.legend()\n",
    "\n",
    "# plt.savefig(\"comparison_\" + str(i) + \".png\")\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inter_pot_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(pot_values_new)):\n",
    "#     plt.plot(inter_pred_LI[i], label=\"LI\", color=\"red\")\n",
    "#     plt.plot(inter_pred_RF[i], label=\"RF\", color=\"green\")\n",
    "#     plt.plot(inter_pred_RNN[i], label=\"RNN\", color=\"orange\")\n",
    "#     plt.title(\n",
    "#         \"Comparison for index \" + str(i) + \", pot_value_new = \" + str(pot_values[i])\n",
    "#     )\n",
    "#     plt.legend()\n",
    "\n",
    "# plt.savefig(\"comparison_\" + str(i) + \".png\")\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_as_sound(audio, output_filename, length):\n",
    "    num_rep = int(length * 44100 / len(audio))\n",
    "    audio_strech = np.tile(audio, num_rep)\n",
    "    sf.write(output_filename, audio_strech, 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(pot_values)):\n",
    "#     create_and_save_as_sound(audios[i], \"original\" + str(i) + \".wav\", 2)\n",
    "#     create_and_save_as_sound(predicted_output_RF[i], \"RF\" + str(i) + \".wav\", 2)\n",
    "#     create_and_save_as_sound(predicted_RNN_values[i], \"RNN\" + str(i) + \".wav\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pot_values_new)):\n",
    "    create_and_save_as_sound(inter_pred_LI[i], \"LI\" + str(i) + \".wav\", 2)\n",
    "    create_and_save_as_sound(inter_pred_RF[i], \"RF\" + str(i) + \".wav\", 2)\n",
    "    create_and_save_as_sound(inter_pred_RNN[i], \"RNN\" + str(i) + \".wav\", 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lin Inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "a = predicted_output_lininter(0.5)\n",
    "stop = timeit.default_timer()\n",
    "LI_time = stop - start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "a = predicted_RF(0.5)\n",
    "stop = timeit.default_timer()\n",
    "RF_time = stop - start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "a = predicted_RNN(0.5)\n",
    "stop = timeit.default_timer()\n",
    "RNN_time = stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([\"Linear Interpolation\", \"Random Forest\", \"RNN\"], [LI_time, RF_time, RNN_time])\n",
    "plt.ylabel(\"Time in seconds\")\n",
    "plt.title(\"Time for prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LI_time)\n",
    "print(RF_time)\n",
    "print(RNN_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_time_factor_LI = LI_time / (1 / 44100)\n",
    "real_time_factor_RF = RF_time / (1 / 44100)\n",
    "real_time_factor_RNN = RNN_time / (1 / 44100)\n",
    "print(real_time_factor_LI)\n",
    "print(real_time_factor_RF)\n",
    "print(real_time_factor_RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(\n",
    "    [\"Linear Interpolation\", \"Random Forest\", \"RNN\"],\n",
    "    [real_time_factor_LI, real_time_factor_RF, real_time_factor_RNN],\n",
    ")\n",
    "plt.ylabel(\"Real time factor\")\n",
    "plt.title(\"Real time factor for prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
